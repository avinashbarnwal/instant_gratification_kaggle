{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm, neighbors, linear_model, neural_network\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import mixture\n",
    "from scipy.stats.mstats import gmean\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "from sklearn.covariance import GraphicalLasso\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 4123\n",
    "\n",
    "cols = [\n",
    "    c for c in train.columns \n",
    "    if c not in ['id', 'target', 'wheezy-copper-turtle-magic']\n",
    "]\n",
    "\n",
    "def get_mean_cov(x,y):\n",
    "    model = GraphicalLasso()\n",
    "    ones = (y==1).astype(bool)\n",
    "    x2 = x[ones]\n",
    "    model.fit(x2)\n",
    "    p1 = model.precision_\n",
    "    m1 = model.location_\n",
    "    \n",
    "    onesb = (y==0).astype(bool)\n",
    "    x2b = x[onesb]\n",
    "    model.fit(x2b)\n",
    "    p2 = model.precision_\n",
    "    m2 = model.location_\n",
    "    \n",
    "    ms = np.stack([m1,m2])\n",
    "    ps = np.stack([p1,p2])\n",
    "    return ms,ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Stop!!!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Stop!!!"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SKIP_COMMIT = True\n",
    "\n",
    "if SKIP_COMMIT:\n",
    "    \n",
    "    # to not waste time on commit\n",
    "    \n",
    "    sub = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "    if sub.shape[0] == 131073:\n",
    "        sub = pd.read_csv('../input/sample_submission.csv')\n",
    "        sub.to_csv('submission.csv', index=False)\n",
    "\n",
    "        raise ValueError('Stop!!!')\n",
    "\n",
    "\n",
    "oof_nusvc = np.zeros(len(train)) \n",
    "preds_nusvc = np.zeros(len(test))\n",
    "\n",
    "oof_nb= np.zeros(len(train)) \n",
    "preds_nb = np.zeros(len(test))\n",
    "\n",
    "oof_lr = np.zeros(len(train)) \n",
    "preds_lr = np.zeros(len(test))\n",
    "\n",
    "oof_qda = np.zeros(len(train)) \n",
    "preds_qda = np.zeros(len(test))\n",
    "\n",
    "oof_lp = np.zeros(len(train))\n",
    "preds_lp = np.zeros(len(test))\n",
    "\n",
    "oof_lgbm = np.zeros(len(train)) \n",
    "preds_lgbm = np.zeros(len(test))\n",
    "\n",
    "oof_gm = np.zeros(len(train)) \n",
    "preds_gm = np.zeros(len(test))\n",
    "\n",
    "oof_rf = np.zeros(len(train)) \n",
    "preds_rf = np.zeros(len(test))\n",
    "\n",
    "\n",
    "params_lgbm_1 = {\n",
    "    'boosting_type': 'goss',\n",
    "    'objective': 'xentropy',\n",
    "    'metric': ['auc'],\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.2887,\n",
    "    'feature_fraction': 0.99,\n",
    "    'bagging_fraction': 0.1575,\n",
    "    'num_threads': -1,\n",
    "    'lambda_l2': 6.382,\n",
    "    'max_bin': 7,\n",
    "    'min_data_in_leaf': 7\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(512):\n",
    "    \n",
    "    print(i, end=' ')\n",
    "    \n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==i] \n",
    "    idx1 = train2.index \n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    idx2 = test2.index\n",
    "    \n",
    "    data = pd.concat(\n",
    "        [\n",
    "            train2,\n",
    "            test2\n",
    "        ],\n",
    "        axis=0\n",
    "    )\n",
    "    train2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_size = train2.shape[0]\n",
    "    \n",
    "    \n",
    "    # remove unnecessary fields\n",
    "    sel = VarianceThreshold(threshold=1.5)\n",
    "    tmp = sel.fit_transform(\n",
    "        data[cols]\n",
    "    )\n",
    "    train3 = tmp[:train_size, :]\n",
    "    test3 = tmp[train_size:, :]\n",
    "    \n",
    "    # scale data for non-QDA methods\n",
    "    ss = StandardScaler()\n",
    "    tmp_scaled = ss.fit_transform(tmp)\n",
    "    \n",
    "    train3_scaled = tmp_scaled[:train_size, :]\n",
    "    test3_scaled = tmp_scaled[train_size:, :]\n",
    "    \n",
    "    # Polynomial features for LogReg\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    tmp_poly = poly.fit_transform(tmp_scaled)\n",
    "    \n",
    "    train3_poly = tmp_poly[:train_size, :]\n",
    "    test3_poly = tmp_poly[train_size:, :]\n",
    "    \n",
    "    # GM features 4\n",
    "    gm_clf_4 = mixture.GaussianMixture(\n",
    "        n_components=4, \n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    gm_tmp_4 = gm_clf_4.fit_predict(tmp).reshape(-1, 1)\n",
    "    \n",
    "    le_4 = OneHotEncoder()\n",
    "    gm_tmp_4 = le_4.fit_transform(gm_tmp_4).todense()\n",
    "    \n",
    "    gm_train3_4 = gm_tmp_4[:train_size, :]\n",
    "    gm_test3_4 = gm_tmp_4[train_size:, :]\n",
    "    \n",
    "    # GM features 6\n",
    "    gm_clf_6 = mixture.GaussianMixture(\n",
    "        n_components=6, \n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    gm_tmp_6 = gm_clf_6.fit_predict(tmp).reshape(-1, 1)\n",
    "    \n",
    "    le_6 = OneHotEncoder()\n",
    "    gm_tmp_6 = le_6.fit_transform(gm_tmp_6).todense()\n",
    "    \n",
    "    gm_train3_6 = gm_tmp_6[:train_size, :]\n",
    "    gm_test3_6 = gm_tmp_6[train_size:, :]\n",
    "    \n",
    "    \n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=11, \n",
    "        random_state=RANDOM_SEED, \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    for train_index, test_index in skf.split(train3, train2['target']):\n",
    "        \n",
    "        train_train_index, train_val_index = train_test_split(\n",
    "            train_index, \n",
    "            test_size=0.3, \n",
    "            random_state=RANDOM_SEED\n",
    "        )\n",
    "        \n",
    "        # LGBM\n",
    "        \n",
    "        train_dataset = lgb.Dataset(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    train3_scaled[train_train_index,:], \n",
    "                    gm_tmp_4[:train_size, :][train_train_index, :].tolist(),\n",
    "                    gm_tmp_6[:train_size, :][train_train_index, :].tolist(),\n",
    "                    train3_poly[train_train_index,:]\n",
    "                )\n",
    "            ),\n",
    "            train2.loc[train_train_index]['target'],\n",
    "            free_raw_data=False\n",
    "        )\n",
    "        \n",
    "        valid_dataset = lgb.Dataset(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    train3_scaled[train_val_index,:],\n",
    "                    gm_tmp_4[:train_size, :][train_val_index, :].tolist(),\n",
    "                    gm_tmp_6[:train_size, :][train_val_index, :].tolist(),\n",
    "                    train3_poly[train_val_index,:]\n",
    "                )\n",
    "            ),\n",
    "            train2.loc[train_val_index]['target'],\n",
    "            free_raw_data=False\n",
    "        )\n",
    "        \n",
    "        gm = lgb.train(\n",
    "            params_lgbm_1,\n",
    "            train_dataset,\n",
    "            num_boost_round=1000,\n",
    "            early_stopping_rounds=20,\n",
    "            valid_sets=(train_dataset, valid_dataset),\n",
    "            valid_names=('train', 'valid'),\n",
    "            verbose_eval=0\n",
    "        )\n",
    "        \n",
    "        oof_lgbm[idx1[test_index]] = gm.predict(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    train3_scaled[test_index,:],\n",
    "                    gm_tmp_4[:train_size, :][test_index, :].tolist(),\n",
    "                    gm_tmp_6[:train_size, :][test_index, :].tolist(),\n",
    "                    train3_poly[test_index,:]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        preds_lgbm[idx2] += gm.predict(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    test3_scaled,\n",
    "                    gm_test3_4.tolist(),\n",
    "                    gm_test3_6.tolist(),\n",
    "                    test3_poly\n",
    "                )\n",
    "            )\n",
    "        ) / skf.n_splits\n",
    "        \n",
    "        # GMM\n",
    "        \n",
    "        ms, ps = get_mean_cov(\n",
    "            train3[train_index, :],\n",
    "            train2.loc[train_index]['target'].values\n",
    "        )\n",
    "        \n",
    "        gm = mixture.GaussianMixture(\n",
    "            n_components=2, \n",
    "            init_params='random', \n",
    "            covariance_type='full', \n",
    "            tol=0.001,\n",
    "            reg_covar=0.001,\n",
    "            max_iter=100,\n",
    "            n_init=1,\n",
    "            means_init=ms,\n",
    "            precisions_init=ps,\n",
    "            random_state=RANDOM_SEED\n",
    "        )\n",
    "        gm.fit(tmp)\n",
    "        oof_gm[idx1[test_index]] = gm.predict_proba(\n",
    "            train3[test_index,:]\n",
    "        )[:, 0]\n",
    "        preds_gm[idx2] += gm.predict_proba(\n",
    "            test3\n",
    "        )[:, 0] / skf.n_splits\n",
    "        \n",
    "        # LabelProp\n",
    "\n",
    "        lp = LabelPropagation(\n",
    "            kernel='rbf', \n",
    "            gamma=0.15301581563198507, \n",
    "            n_jobs=-1\n",
    "        )\n",
    "        lp.fit(\n",
    "            train3_scaled[train_index,:],\n",
    "            train2.loc[train_index]['target']\n",
    "        )\n",
    "        oof_lp[idx1[test_index]] = lp.predict_proba(\n",
    "            train3_scaled[test_index, :]\n",
    "        )[:,1]\n",
    "        preds_lp[idx2] += lp.predict_proba(\n",
    "            test3_scaled\n",
    "        )[:,1] / skf.n_splits\n",
    "        \n",
    "        # nuSVC\n",
    "        \n",
    "        clf = NuSVC(\n",
    "            probability=True, \n",
    "            kernel='poly', \n",
    "            degree=2,\n",
    "            gamma='auto', \n",
    "            random_state=RANDOM_SEED, \n",
    "            nu=0.27312143533915767, \n",
    "            coef0=0.4690615598786931\n",
    "        )\n",
    "        \n",
    "        clf.fit(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    train3_scaled[train_index,:], \n",
    "                    gm_train3_4[train_index, :],\n",
    "                    gm_train3_6[train_index, :]\n",
    "                )\n",
    "            ),\n",
    "            train2.loc[train_index]['target']\n",
    "        )\n",
    "        oof_nusvc[idx1[test_index]] = clf.predict_proba(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    train3_scaled[test_index,:],\n",
    "                    gm_train3_4[test_index, :],\n",
    "                    gm_train3_6[test_index, :]\n",
    "                )\n",
    "            )\n",
    "        )[:,1]\n",
    "        \n",
    "        preds_nusvc[idx2] += clf.predict_proba(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    test3_scaled, \n",
    "                    gm_test3_4,\n",
    "                    gm_test3_6\n",
    "                )\n",
    "            )\n",
    "        )[:,1] / skf.n_splits\n",
    "        \n",
    "        # RF\n",
    "        \n",
    "        clf = RandomForestClassifier(\n",
    "            max_depth=7, \n",
    "            n_jobs=-1, \n",
    "            n_estimators=20,\n",
    "            random_state=RANDOM_SEED,\n",
    "            max_features=0.4995,\n",
    "            min_samples_leaf=5,\n",
    "            min_samples_split=10\n",
    "        )\n",
    "        \n",
    "        clf.fit(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    train3_scaled[train_index,:], \n",
    "                    gm_train3_4[train_index, :],\n",
    "                    gm_train3_6[train_index, :]\n",
    "                )\n",
    "            ),\n",
    "            train2.loc[train_index]['target']\n",
    "        )\n",
    "        oof_rf[idx1[test_index]] = clf.predict_proba(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    train3_scaled[test_index,:],\n",
    "                    gm_train3_4[test_index, :],\n",
    "                    gm_train3_6[test_index, :]\n",
    "                )\n",
    "            )\n",
    "        )[:,1]\n",
    "        \n",
    "        preds_rf[idx2] += clf.predict_proba(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    test3_scaled, \n",
    "                    gm_test3_4,\n",
    "                    gm_test3_6\n",
    "                )\n",
    "            )\n",
    "        )[:,1] / skf.n_splits\n",
    "\n",
    "        # QDA\n",
    "        clf = QuadraticDiscriminantAnalysis(\n",
    "            reg_param=0.5674164995882528\n",
    "        )\n",
    "        clf.fit(\n",
    "            train3[train_index,:],\n",
    "            train2.loc[train_index]['target']\n",
    "        )\n",
    "        oof_qda[idx1[test_index]] += clf.predict_proba(\n",
    "            train3[test_index, :]\n",
    "        )[:,1]\n",
    "        preds_qda[idx2] += clf.predict_proba(\n",
    "            test3\n",
    "        )[:,1] / skf.n_splits\n",
    "        \n",
    "        # LogReg Poly\n",
    "        \n",
    "        clf = linear_model.LogisticRegression(\n",
    "            solver='saga',\n",
    "            penalty='l2',\n",
    "            C=0.01,\n",
    "            tol=0.001,\n",
    "            random_state=RANDOM_SEED\n",
    "        )\n",
    "        clf.fit(\n",
    "            train3_poly[train_index,:],\n",
    "            train2.loc[train_index]['target']\n",
    "        )\n",
    "        oof_lr[idx1[test_index]] = clf.predict_proba(\n",
    "            train3_poly[test_index,:]\n",
    "        )[:,1]\n",
    "        preds_lr[idx2] += clf.predict_proba(\n",
    "            test3_poly\n",
    "        )[:,1] / skf.n_splits\n",
    "        \n",
    "        # GaussianNB with GM 6\n",
    "        \n",
    "        clf = GaussianNB()\n",
    "        clf.fit(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    train3_scaled[train_index,:], \n",
    "                    gm_train3_6[train_index, :],\n",
    "                    gm_train3_4[train_index, :]\n",
    "                )\n",
    "            ),\n",
    "            train2.loc[train_index]['target']\n",
    "        )\n",
    "        oof_nb[idx1[test_index]] = clf.predict_proba(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    train3_scaled[test_index,:],\n",
    "                    gm_train3_6[test_index, :],\n",
    "                    gm_train3_4[test_index, :]\n",
    "                )\n",
    "            )\n",
    "        )[:,1]\n",
    "        \n",
    "        preds_nb[idx2] += clf.predict_proba(\n",
    "            np.hstack(\n",
    "                (\n",
    "                    test3_scaled,\n",
    "                    gm_test3_6,\n",
    "                    gm_test3_4\n",
    "                )\n",
    "            )\n",
    "        )[:,1] / skf.n_splits\n",
    "\n",
    "        \n",
    "print('\\nsvcnu', roc_auc_score(train['target'], oof_nusvc))\n",
    "print('gm', roc_auc_score(train['target'], oof_gm))\n",
    "print('qda', roc_auc_score(train['target'], oof_qda))\n",
    "print('log reg poly', roc_auc_score(train['target'], oof_lr))\n",
    "print('gnb', roc_auc_score(train['target'], oof_nb))\n",
    "print('lp', roc_auc_score(train['target'], oof_lp))\n",
    "print('lgbm', roc_auc_score(train['target'], oof_lgbm))\n",
    "print('rf', roc_auc_score(train['target'], oof_rf))\n",
    "\n",
    "oof_qda = oof_qda.reshape(-1, 1)\n",
    "preds_qda = preds_qda.reshape(-1, 1)\n",
    "\n",
    "oof_lr = oof_lr.reshape(-1, 1)\n",
    "preds_lr = preds_lr.reshape(-1, 1)\n",
    "\n",
    "oof_nusvc = oof_nusvc.reshape(-1, 1)\n",
    "preds_nusvc = preds_nusvc.reshape(-1, 1)\n",
    "\n",
    "oof_nb = oof_nb.reshape(-1, 1)\n",
    "preds_nb = preds_nb.reshape(-1, 1)\n",
    "\n",
    "oof_lp = oof_lp.reshape(-1, 1)\n",
    "preds_lp = preds_lp.reshape(-1, 1)\n",
    "\n",
    "oof_gm = oof_gm.reshape(-1, 1)\n",
    "preds_gm = preds_gm.reshape(-1, 1)\n",
    "\n",
    "oof_lgbm = oof_lgbm.reshape(-1, 1)\n",
    "preds_lgbm = preds_lgbm.reshape(-1, 1)\n",
    "\n",
    "oof_rf = oof_rf.reshape(-1, 1)\n",
    "preds_rf = preds_rf.reshape(-1, 1)\n",
    "\n",
    "tr_2 = np.concatenate(\n",
    "    (\n",
    "        oof_qda,\n",
    "        oof_nusvc,\n",
    "        oof_lr,\n",
    "        oof_nb,\n",
    "        oof_lp,\n",
    "        oof_gm,\n",
    "        oof_lgbm,\n",
    "        oof_rf\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "te_2 = np.concatenate(\n",
    "    (\n",
    "        preds_qda, \n",
    "        preds_nusvc, \n",
    "        preds_lr, \n",
    "        preds_nb,\n",
    "        preds_lp,\n",
    "        preds_gm,\n",
    "        preds_lgbm,\n",
    "        preds_rf\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(np.corrcoef(tr_2, rowvar=False))\n",
    "\n",
    "params = {\n",
    "        'boosting_type': 'goss',\n",
    "        'objective': 'xentropy',\n",
    "        'metric': ['auc'],\n",
    "        'num_leaves': 3,\n",
    "        'learning_rate': 0.2,\n",
    "        'feature_fraction': 0.4,\n",
    "        'bagging_fraction': 0.4,\n",
    "        #'bagging_freq': 5,\n",
    "        'num_threads': -1\n",
    "    }\n",
    "\n",
    "params.update(\n",
    "    {\n",
    "        #'bagging_fraction': 0.9687497922020039, \n",
    "        #'bagging_freq': 100, \n",
    "        #'feature_fraction': 0.7578027095458152, \n",
    "        'lambda_l2': 4.871836452096843, \n",
    "        #'learning_rate': 0.41230192513715164, \n",
    "        'max_bin': 20, \n",
    "        'num_leaves': 8\n",
    "    }\n",
    ")\n",
    "\n",
    "oof_boosting_2_bad_cv = np.zeros(train.shape[0])\n",
    "pred_te_boosting_2_bad_cv = np.zeros(test.shape[0])\n",
    "\n",
    "\n",
    "train2 = train.copy()\n",
    "train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=11, \n",
    "    random_state=RANDOM_SEED, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "POWER = 3.311107576798093\n",
    "\n",
    "for train_index, test_index in skf.split(tr_2, train2['target']):\n",
    "    \n",
    "    train_dataset = lgb.Dataset(\n",
    "        np.hstack(\n",
    "            (\n",
    "                tr_2[train_index, :],\n",
    "                tr_2[train_index, :]  ** POWER\n",
    "            )\n",
    "        ),\n",
    "        train2['target'][train_index],\n",
    "        free_raw_data=False\n",
    "    )\n",
    "    valid_dataset = lgb.Dataset(\n",
    "        np.hstack(\n",
    "            (\n",
    "                tr_2[test_index, :] ,\n",
    "                tr_2[test_index, :]  ** POWER\n",
    "            )\n",
    "        ),\n",
    "        train2['target'][test_index],\n",
    "        free_raw_data=False\n",
    "    )\n",
    "\n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        train_dataset,\n",
    "        num_boost_round=1000,\n",
    "        early_stopping_rounds=100,\n",
    "        valid_sets=(train_dataset, valid_dataset),\n",
    "        valid_names=('train', 'valid'),\n",
    "        verbose_eval=100\n",
    "    )\n",
    "\n",
    "    oof_boosting_2_bad_cv[test_index] = gbm.predict(\n",
    "        np.hstack(\n",
    "            (\n",
    "                tr_2[test_index, :],\n",
    "                tr_2[test_index, :] ** POWER\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    pred_te_boosting_2_bad_cv += gbm.predict(\n",
    "        np.hstack(\n",
    "            (\n",
    "                te_2,\n",
    "                te_2 ** POWER\n",
    "            )\n",
    "        )\n",
    "    ) / skf.n_splits\n",
    "\n",
    "    \n",
    "print('gnb', roc_auc_score(train['target'], oof_boosting_2_bad_cv))\n",
    "\n",
    "##############\n",
    "# SAVE RESULTS\n",
    "##############\n",
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub['target'] = pred_te_boosting_2_bad_cv\n",
    "sub.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
